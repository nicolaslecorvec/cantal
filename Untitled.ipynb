{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ad54b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import linregress\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from pyproj import Transformer\n",
    "from shapely.geometry import Polygon\n",
    "import branca.colormap\n",
    "import folium\n",
    "import contextily as ctx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from datetime import datetime\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.ticker import FormatStrFormatter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e914531c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Specify the path to your CSV file\n",
    "\n",
    "file_path = '/mnt/d/Optimaize/Cantal/EGMS_L3_E37N24_100km_U/EGMS_L3_E37N24_100km_U.csv'\n",
    "\n",
    "# Use pandas to read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec177a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of the 'rmse' column\n",
    "plt.hist(df['rmse'], bins=30, edgecolor='black')\n",
    "plt.xlabel('RMSE')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of RMSE Values')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8a39bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rmse'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb482951",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['rmse','mean_velocity','acceleration','seasonality']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7689471f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the dates are stored in columns 11 to 373\n",
    "date_columns = df.columns[11:374]\n",
    "\n",
    "# Select the displacement values from the first row for these date columns\n",
    "displacement_values = df.loc[0, date_columns]\n",
    "\n",
    "# Convert the date column names to datetime objects for plotting\n",
    "dates = pd.to_datetime(date_columns, format='%Y%m%d')\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(dates, displacement_values, marker='o', linestyle='-')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Displacement (mm)')\n",
    "plt.title('Displacement over Time')\n",
    "plt.xticks(rotation=45)  # Rotate the x-axis labels for better readability\n",
    "plt.tight_layout()  # Adjust layout for better fit\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b598c3",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## STL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fab09d5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "\n",
    "# Assuming df is your DataFrame and the necessary libraries are imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2bb24f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Convert displacement_values to a numeric type\n",
    "displacement_values = pd.to_numeric(displacement_values, errors='coerce')\n",
    "\n",
    "# Drop any NaN values that result from conversion errors\n",
    "displacement_values = displacement_values.dropna()\n",
    "\n",
    "# Make sure the index of displacement_values is the dates DatetimeIndex\n",
    "displacement_values.index = dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67dc80c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Perform STL decomposition with a period of approximately 61 (for data every 6 days)\n",
    "stl = STL(displacement_values, seasonal=61)\n",
    "result = stl.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d311bf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "result.seasonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179de30b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plotting the components\n",
    "fig, axes = plt.subplots(4, 1, figsize=(10, 8), sharex=True)\n",
    "\n",
    "# Plot the observed data\n",
    "axes[0].plot(dates, displacement_values, label='Observed')\n",
    "axes[0].set_ylabel('Observed')\n",
    "axes[0].legend()\n",
    "\n",
    "# Plot the trend component\n",
    "axes[1].plot(dates, result.trend, label='Trend')\n",
    "axes[1].set_ylabel('Trend')\n",
    "axes[1].legend()\n",
    "\n",
    "# Plot the seasonal component\n",
    "axes[2].plot(dates, result.seasonal, label='Seasonal')\n",
    "axes[2].set_ylabel('Seasonal')\n",
    "axes[2].legend()\n",
    "\n",
    "# Plot the residual component\n",
    "axes[3].plot(dates, result.resid, label='Residual')\n",
    "axes[3].set_ylabel('Residual')\n",
    "axes[3].legend()\n",
    "\n",
    "# Set the x-axis labels and rotate them for better readability\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Date')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b0877c",
   "metadata": {},
   "source": [
    "## gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdfef1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer.from_crs('epsg:3035', 'epsg:4326', always_xy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bfca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the transformation\n",
    "coords = df.apply(\n",
    "    lambda row: transformer.transform(row['easting'], row['northing']), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ffc8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the transformed coordinates back to the original DataFrame using loc\n",
    "for idx, (lon, lat) in coords.iteritems():\n",
    "    df.loc[idx, 'longitude'] = lon\n",
    "    df.loc[idx, 'latitude'] = lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358472a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d941ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming high_r_squared_positive_df is your DataFrame with longitude and latitude\n",
    "# Convert DataFrame to GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    df, \n",
    "    geometry=gpd.points_from_xy(df.longitude, df.latitude),\n",
    "    crs=\"EPSG:4326\"  # Set the coordinate reference system to WGS84 (lat/lon)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21afaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the dates are stored in columns 11 to 373\n",
    "date_columns = gdf.columns[11:374]\n",
    "\n",
    "# Select the displacement values from the first row for these date columns\n",
    "displacement_values = gdf.loc[0, date_columns]\n",
    "\n",
    "# Convert the date column names to datetime objects for plotting\n",
    "dates = pd.to_datetime(date_columns, format='%Y%m%d')\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(dates, displacement_values, marker='o', linestyle='-')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Displacement (mm)')\n",
    "plt.title('Displacement over Time')\n",
    "plt.xticks(rotation=45)  # Rotate the x-axis labels for better readability\n",
    "plt.tight_layout()  # Adjust layout for better fit\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091cd15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd21575",
   "metadata": {},
   "source": [
    "## Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5875bd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming gdf is your pre-loaded GeoDataFrame with the 'longitude' and 'latitude' columns\n",
    "\n",
    "# Function to create a scatter mapbox with Plotly\n",
    "def create_interactive_map(gdf):\n",
    "    fig = px.scatter_mapbox(gdf,\n",
    "                            lat=\"latitude\",\n",
    "                            lon=\"longitude\",\n",
    "                            color=\"mean_velocity\", # Example: color points by mean velocity\n",
    "                            size=\"mean_velocity_std\", # Example: size points by mean velocity standard deviation\n",
    "                            color_continuous_scale=px.colors.cyclical.IceFire,\n",
    "                            size_max=15,\n",
    "                            zoom=10)\n",
    "    \n",
    "    fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "    fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "    return fig\n",
    "\n",
    "# This will create and display the interactive map in your Jupyter notebook\n",
    "fig = create_interactive_map(gdf)\n",
    "fig.show()\n",
    "\n",
    "# To enable click events to show the displacement time series, you would need to\n",
    "# either transition to Dash for a full web app or write custom JavaScript callbacks\n",
    "# (which is beyond the scope of a simple Jupyter notebook interaction).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba8fa19",
   "metadata": {},
   "source": [
    "## Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7882ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming gdf is your GeoDataFrame loaded with your data\n",
    "\n",
    "# Function to create a scatter mapbox with Plotly\n",
    "def create_interactive_map(gdf):\n",
    "    fig = px.scatter_mapbox(gdf,\n",
    "                            lat=\"latitude\",\n",
    "                            lon=\"longitude\",\n",
    "                            # Assuming you have a 'mean_velocity' column to color the points\n",
    "                            color=\"mean_velocity\",\n",
    "                            size=\"mean_velocity_std\",\n",
    "                            hover_name=gdf.index, # show index in hover data\n",
    "                            zoom=3,\n",
    "                            height=300)\n",
    "    fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "    fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "    return fig\n",
    "\n",
    "# Streamlit layout\n",
    "st.title('Ground Displacement Interactive Map')\n",
    "\n",
    "# Display interactive map in Streamlit\n",
    "fig = create_interactive_map(gdf)\n",
    "st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "# Instructions for user interaction\n",
    "st.write(\"Click on a point in the map to view displacement time series.\")\n",
    "\n",
    "# Mock function to get time series data for a selected point\n",
    "def get_time_series_data(selected_point):\n",
    "    # You would fetch the real time series data based on the selected point\n",
    "    # Here, we just return a sample Pandas series\n",
    "    dates = pd.date_range(start=\"2020-01-01\", periods=100, freq='W')\n",
    "    data = pd.Series(data=range(100), index=dates)\n",
    "    return data\n",
    "\n",
    "# User selects a point ID (you could create a more dynamic selection method)\n",
    "selected_point = st.selectbox('Select a Point ID', gdf.index)\n",
    "\n",
    "# Show time series for selected point\n",
    "if st.button('Show Time Series'):\n",
    "    ts_data = get_time_series_data(selected_point)\n",
    "    ts_fig = px.line(ts_data, title='Displacement over Time')\n",
    "    st.plotly_chart(ts_fig, use_container_width=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367a371c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "834a9f5c",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b1b151",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8652bc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Function to count NaNs and calculate the ratio of NaNs in a row\n",
    "def nan_info(row):\n",
    "    nans = np.isnan(row).sum()\n",
    "    total = len(row)\n",
    "    ratio = nans / total\n",
    "    return pd.Series([nans, ratio], index=['nans', 'nan_ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9661f4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Apply the function to the displacement columns of the DataFrame\n",
    "nan_results = df.iloc[:, 11:374].apply(nan_info, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c55f2f0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nan_results.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac3e6bf",
   "metadata": {},
   "source": [
    "## linear regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7e4f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to apply linear regression and calculate the differences\n",
    "def calculate_differences(row):\n",
    "    # Extract the y values (displacement) for the linear regression\n",
    "    y_values = row[11:374].values\n",
    "    # Create an array of x values corresponding to the dates\n",
    "    x_values = np.arange(len(y_values))\n",
    "    # Perform the linear regression\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(x_values, y_values.astype(float))\n",
    "    # Calculate the estimated displacement difference based on the regression\n",
    "    regression_diff = (slope * (len(x_values) - 1) + intercept) - (slope * 0 + intercept)\n",
    "    # Calculate the actual displacement difference based on the real values\n",
    "    real_diff = y_values[-1] - y_values[0]\n",
    "    # Return the slope, intercept, r_squared, regression_diff, and real_diff\n",
    "    return pd.Series([slope, intercept, r_value ** 2, regression_diff, real_diff],\n",
    "                     index=['slope', 'intercept', 'r_squared', 'regression_diff', 'real_diff'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc38ed06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to each row of the DataFrame and create new columns\n",
    "df_tendency = df.apply(calculate_differences, axis=1)\n",
    "df_tendency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b652ef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of the 'rmse' column\n",
    "plt.hist(df_tendency['r_squared'], bins=30, edgecolor='black')\n",
    "plt.xlabel('r_squared')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of r_squared Values')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011826d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tendency.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3af766",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_linregress = pd.concat([df[['easting','northing','height','rmse','mean_velocity','acceleration','seasonality']],df_tendency],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4a9d4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_linregress.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa628667",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d79722",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = -0.03\n",
    "vmax = 0.03\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots()\n",
    "scatter = ax.scatter(df_linregress['easting'],\n",
    "                     df_linregress['northing'],\n",
    "                     c=df_linregress['slope'],\n",
    "                     cmap='bwr',\n",
    "                     vmin= vmin, #-max(abs(df['slope'])),\n",
    "                     vmax= vmax, #max(abs(df['slope'])),\n",
    "                     s=1)  # smaller points\n",
    "\n",
    "# Add a colorbar\n",
    "cbar = plt.colorbar(scatter, ax=ax)\n",
    "cbar.set_label('Slope')\n",
    "\n",
    "# Correctly setting where white (0) should be in the colormap\n",
    "cbar.set_ticks([vmax, 0, vmax])  # Use a list for tick locations\n",
    "cbar.set_ticklabels([f'{vmin}', '0', f'{vmax}'])  # Use a list for tick labels\n",
    "\n",
    "# Axis labels\n",
    "ax.set_xlabel('Easting')\n",
    "ax.set_ylabel('Northing')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06e0b40",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## test r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d199410d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import linregress\n",
    "\n",
    "# Assuming df is your original DataFrame containing the time series and df_tendency is already computed\n",
    "\n",
    "# Segmenting the DataFrame based on r_squared values\n",
    "thresholds = df_tendency['r_squared'].quantile([0.33, 0.66]).values\n",
    "\n",
    "low_r_squared = df_tendency[df_tendency['r_squared'] <= thresholds[0]]\n",
    "medium_r_squared = df_tendency[(df_tendency['r_squared'] > thresholds[0]) & (df_tendency['r_squared'] <= thresholds[1])]\n",
    "high_r_squared = df_tendency[df_tendency['r_squared'] > thresholds[1]]\n",
    "\n",
    "# Sample 10 random rows from each segment\n",
    "low_samples = low_r_squared.sample(n=10, random_state=1)\n",
    "medium_samples = medium_r_squared.sample(n=10, random_state=1)\n",
    "high_samples = high_r_squared.sample(n=10, random_state=1)\n",
    "\n",
    "# Function to plot time series\n",
    "def plot_time_series(samples, title):\n",
    "    fig, axs = plt.subplots(10, 1, figsize=(10, 20), sharex=True)\n",
    "    for i, (index, row) in enumerate(samples.iterrows()):\n",
    "        y_values = df.loc[index][11:374].values\n",
    "        axs[i].plot(y_values)\n",
    "        axs[i].set_title(f\"{title} r_squared Sample {i+1} (r_squared: {row['r_squared']:.2f})\")\n",
    "        axs[i].set_ylabel('Displacement')\n",
    "    \n",
    "    axs[-1].set_xlabel('Time Index')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plotting the samples\n",
    "plot_time_series(low_samples, \"Low\")\n",
    "plot_time_series(medium_samples, \"Medium\")\n",
    "plot_time_series(high_samples, \"High\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e382d9c5",
   "metadata": {},
   "source": [
    "## linear regression high r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9ccfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \"high\" as being in the top third of r_squared values\n",
    "high_r_squared_threshold = df_linregress['r_squared'].quantile(0.66)  # Adjust quantile as needed\n",
    "\n",
    "# Filter for high r_squared values\n",
    "high_r_squared_df = df_linregress[df_linregress['r_squared'] > high_r_squared_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15c403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = -0.03\n",
    "vmax = 0.03\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots()\n",
    "scatter = ax.scatter(high_r_squared_df['easting'],\n",
    "                     high_r_squared_df['northing'],\n",
    "                     c=high_r_squared_df['slope'],\n",
    "                     cmap='bwr',\n",
    "                     vmin=vmin,  # Using the provided vmin\n",
    "                     vmax=vmax,   # Using the provided vmax\n",
    "                     s=0.01)  # Keeping the small points\n",
    "\n",
    "# Add a colorbar\n",
    "cbar = plt.colorbar(scatter, ax=ax)\n",
    "cbar.set_label('Slope')\n",
    "\n",
    "# Correctly setting where white (0) should be in the colormap\n",
    "# Note: There was a mistake in setting the ticks in your original code; it should likely be [vmin, 0, vmax]\n",
    "# Correctly setting where white (0) should be in the colormap\n",
    "cbar.set_ticks([vmax, 0, vmax])  # Use a list for tick locations\n",
    "cbar.set_ticklabels([f'{vmin}', '0', f'{vmax}'])  # Use a list for tick labels\n",
    "\n",
    "# Axis labels\n",
    "ax.set_xlabel('Easting')\n",
    "ax.set_ylabel('Northing')\n",
    "plt.title('Slope for High r_squared Values')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450ede64",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## positive displacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12b2e73",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "high_r_squared_positive_df = high_r_squared_df[high_r_squared_df['slope'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e507bd6d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "high_r_squared_positive_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6936edb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vmin = 0\n",
    "vmax = max(high_r_squared_positive_df['slope'])\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots()\n",
    "scatter = ax.scatter(high_r_squared_positive_df['easting'],\n",
    "                     high_r_squared_positive_df['northing'],\n",
    "                     c=high_r_squared_positive_df['slope'],\n",
    "                     cmap='Reds',\n",
    "                     vmin=vmin,  # Using the provided vmin\n",
    "                     vmax=vmax,   # Using the provided vmax\n",
    "                     s=1)  # Keeping the small points\n",
    "\n",
    "# Add a colorbar\n",
    "cbar = plt.colorbar(scatter, ax=ax)\n",
    "cbar.set_label('Slope')\n",
    "\n",
    "# Correctly setting where white (0) should be in the colormap\n",
    "# Note: There was a mistake in setting the ticks in your original code; it should likely be [vmin, 0, vmax]\n",
    "# Correctly setting where white (0) should be in the colormap\n",
    "cbar.set_ticks([vmax, 0, vmax])  # Use a list for tick locations\n",
    "cbar.set_ticklabels([f'{vmin}', '0', f'{vmax}'])  # Use a list for tick labels\n",
    "\n",
    "# Set the format of the colorbar labels\n",
    "cbar.formatter = FormatStrFormatter('%.2f')  # This sets the labels to two decimal places\n",
    "cbar.update_ticks()\n",
    "\n",
    "# Axis labels\n",
    "ax.set_xlabel('Easting')\n",
    "ax.set_ylabel('Northing')\n",
    "plt.title('Slope for High r_squared and positive Values')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3ff41e",
   "metadata": {},
   "source": [
    "## transform into a gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9684b6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_r_squared_positive_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2233cf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transformer object for EPSG:3035 (ETRS89-LAEA) to EPSG:4326 (WGS84)\n",
    "transformer = Transformer.from_crs('epsg:3035', 'epsg:4326', always_xy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641332c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the transformation\n",
    "coords = high_r_squared_positive_df.apply(\n",
    "    lambda row: transformer.transform(row['easting'], row['northing']), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912e0e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the transformed coordinates back to the original DataFrame using loc\n",
    "for idx, (lon, lat) in coords.iteritems():\n",
    "    high_r_squared_positive_df.loc[idx, 'longitude'] = lon\n",
    "    high_r_squared_positive_df.loc[idx, 'latitude'] = lat\n",
    "\n",
    "# If the original DataFrame was named df, then you'd update df like this\n",
    "# for idx, (lon, lat) in coords.iteritems():\n",
    "#     df.loc[idx, 'longitude'] = lon\n",
    "#     df.loc[idx, 'latitude'] = lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a78a0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_r_squared_positive_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dd0385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming high_r_squared_positive_df is your DataFrame with longitude and latitude\n",
    "# Convert DataFrame to GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    high_r_squared_positive_df, \n",
    "    geometry=gpd.points_from_xy(high_r_squared_positive_df.longitude, high_r_squared_positive_df.latitude),\n",
    "    crs=\"EPSG:4326\"  # Set the coordinate reference system to WGS84 (lat/lon)\n",
    ")\n",
    "\n",
    "# Now you can work with 'gdf' as a GeoDataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56606704",
   "metadata": {},
   "source": [
    "## Cantal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fd8a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL to the GeoJSON file\n",
    "url = \"https://france-geojson.gregoiredavid.fr/repo/departements/15-cantal/communes-15-cantal.geojson\"\n",
    "\n",
    "# Read the GeoJSON file directly from the URL\n",
    "cantal_communes = gpd.read_file(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57035528",
   "metadata": {},
   "outputs": [],
   "source": [
    "cantal_communes.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc5a548",
   "metadata": {},
   "outputs": [],
   "source": [
    "cantal_communes.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a217f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'high_r_squared_positive_df' is your DataFrame as provided\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    high_r_squared_positive_df,\n",
    "    geometry=gpd.points_from_xy(high_r_squared_positive_df.longitude, high_r_squared_positive_df.latitude),\n",
    "    crs='EPSG:4326'\n",
    ")\n",
    "\n",
    "# Convert the GeoDataFrame to Web Mercator CRS\n",
    "gdf = gdf.to_crs(epsg=3857)\n",
    "\n",
    "# Read the Cantal communes GeoJSON\n",
    "cantal_communes = gpd.read_file(url)\n",
    "# Make sure the communes GeoDataFrame is in the same CRS as the points\n",
    "cantal_communes = cantal_communes.to_crs(epsg=3857)\n",
    "\n",
    "# Start plotting\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "# Plot the communes\n",
    "cantal_communes.boundary.plot(ax=ax, edgecolor='black')\n",
    "# Plot the points\n",
    "gdf.plot(ax=ax, column='slope', cmap='Reds', legend=True, \n",
    "         legend_kwds={'shrink': 0.6, 'label': 'Slope'})\n",
    "\n",
    "# Add a basemap\n",
    "ctx.add_basemap(ax, source=ctx.providers.CartoDB.Positron)\n",
    "\n",
    "# Remove axis off\n",
    "ax.set_axis_off()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f5be78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the GeoDataFrame is in EPSG:4326 for folium\n",
    "cantal_communes_wgs84 = cantal_communes.to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97d4cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might not need to do this step if you're just aiming to center the map visually.\n",
    "# Projecting to a common projection used in France for more accurate centroid calculation\n",
    "cantal_communes_projected = cantal_communes.to_crs(epsg=2154)  # Lambert-93\n",
    "\n",
    "# Now calculate the mean of centroids in the projected CRS\n",
    "center_y = cantal_communes_projected.geometry.centroid.y.mean()\n",
    "center_x = cantal_communes_projected.geometry.centroid.x.mean()\n",
    "\n",
    "# If needed, convert these centroid coordinates back to EPSG:4326 for use with Folium\n",
    "transformer = Transformer.from_crs('epsg:2154', 'epsg:4326', always_xy=True)\n",
    "center_x, center_y = transformer.transform(center_x, center_y)\n",
    "\n",
    "# Now use these centroid coordinates to center your Folium map\n",
    "m = folium.Map(\n",
    "    location=[center_y, center_x], \n",
    "    zoom_start=8  # Adjust zoom level as needed\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71d5d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium import FeatureGroup\n",
    "from branca.colormap import linear\n",
    "\n",
    "# Assuming gdf_wgs84 is your GeoDataFrame in EPSG:4326\n",
    "# First, create a colormap\n",
    "colormap = linear.Reds_09.scale(gdf_wgs84['slope'].min(), gdf_wgs84['slope'].max())\n",
    "colormap.caption = 'Slope'\n",
    "\n",
    "\n",
    "# Initialize the folium map centered around the mean coordinates of the communes\n",
    "m = folium.Map(\n",
    "    location=[\n",
    "        cantal_communes_wgs84.geometry.centroid.y.mean(), \n",
    "        cantal_communes_wgs84.geometry.centroid.x.mean()\n",
    "    ], \n",
    "    zoom_start=8  # Adjust zoom level as needed\n",
    ")\n",
    "\n",
    "# Add points to the map\n",
    "for _, row in gdf_wgs84.iterrows():\n",
    "    folium.Circle(\n",
    "        location=[row.geometry.y, row.geometry.x],\n",
    "        radius=50,  # Adjust the size of the circle markers\n",
    "        color=colormap(row['slope']),  # Use the colormap to determine the color\n",
    "        fill=True,\n",
    "        fill_color=colormap(row['slope']),\n",
    "        fill_opacity=0.7,\n",
    "        popup=folium.Popup(f\"Slope: {row['slope']}\", parse_html=True),\n",
    "    ).add_to(m)\n",
    "\n",
    "# Add the Cantal communes as a GeoJSON layer\n",
    "folium.GeoJson(\n",
    "    cantal_communes_wgs84,\n",
    "    style_function=lambda feature: {'color': 'blue', 'weight': 2, 'fillOpacity': 0},\n",
    "    name='Cantal Communes'\n",
    ").add_to(m)\n",
    "\n",
    "# Add the colormap to the map\n",
    "colormap.add_to(m)\n",
    "\n",
    "# Optionally, add layer control to toggle the GeoJSON layer\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "# Display the map\n",
    "m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e72f8b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# STL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef1b692",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc227a7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7bd9fb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load your dataframe here, and ensure date_columns and df are defined correctly\n",
    "\n",
    "# Assuming your dates are in a 'YYYYMMDD' format in the column names\n",
    "dates = pd.to_datetime(date_columns, format='%Y%m%d')\n",
    "\n",
    "# Create a DataFrame to store the STL results\n",
    "stl_results = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    # Create a time series for the row with the dates as the index\n",
    "    time_series = pd.Series(data=row[date_columns].values, index=dates)\n",
    "    \n",
    "    # Ensure that the series has a defined frequency (e.g., 'D' for daily)\n",
    "    time_series = time_series.asfreq('D')  # or another appropriate frequency\n",
    "    \n",
    "    # Perform STL decomposition with an explicit period if needed\n",
    "    stl = sm.tsa.STL(time_series, period=13)  # Modify '13' to your specific period\n",
    "    result = stl.fit()\n",
    "    \n",
    "    # Store the STL results in a dictionary for each row\n",
    "    stl_results.append({\n",
    "        'trend': result.trend,\n",
    "        'seasonal': result.seasonal,\n",
    "        'resid': result.resid,\n",
    "        'weights': result.weights,\n",
    "    })\n",
    "\n",
    "# Process the stl_results as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990185c3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
